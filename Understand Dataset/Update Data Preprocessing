import pandas as pd
import numpy as np

# Load dataset (giả sử dữ liệu từ file US_youtube_trending_data.csv)
df = pd.read_csv('US_youtube_trending_data.csv')

# Kiểm tra các columns và thông tin cơ bản
print("Columns:", df.columns.tolist())
print("Shape:", df.shape)
print("Missing values:\n", df.isnull().sum())

columns_to_drop = [
    'thumbnail_link', 'comments_disabled', 'ratings_disabled',
    'description', 'channelId', 'channelTitle'
]
df = df.drop(columns=columns_to_drop, errors='ignore')  # 
# Kiểm tra duplicate dựa trên video_id (mỗi video chỉ nên xuất hiện 1 lần trong trending)
df = df.drop_duplicates(subset=['video_id'], keep='first')
# Fill missing values cho numeric columns bằng median
numeric_cols = ['view_count', 'likes', 'dislikes', 'comment_count']
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())

# Fill missing tags với empty string
df['tags'] = df['tags'].fillna('')
# Chuyển publishedAt và trending_date sang datetime
df['publishedAt'] = pd.to_datetime(df['publishedAt'])
df['trending_date'] = pd.to_datetime(df['trending_date'])

# Tính thời gian từ lúc publish đến khi trending (đơn vị: giờ)
df['hours_to_trend'] = (df['trending_date'] - df['publishedAt']).dt.total_seconds() / 3600

# Kiểm tra phân phối của target variable
print(df['hours_to_trend'].describe())
# Giả sử có file JSON chứa mapping categoryId sang tên category
import json
with open('US_category_id.json', 'r') as f:
    category_map = json.load(f)

# Tạo dictionary để map categoryId sang category name
category_id_to_name = {int(item['id']): item['snippet']['title'] for item in category_map['items']}
df['category_name'] = df['categoryId'].map(category_id_to_name)

# Kiểm tra các categories
print("Unique categories:", df['category_name'].unique())

# Title length
df['title_length'] = df['title'].str.len()

def clean_tags(tag):
    if tag == '[none]': return []
    return tag.lower().replace('"','').split('|')
df['tags'] = df['tags'].apply(clean_tags)

def clean_titles(title):
    tokens = title.lower().split()
    cleaned = []
    sw = set(stopwords.words('english'))
    for token in tokens:
        if token.startswith('$') or token.isnumeric() or not token.isalnum() or token in sw:  # Remove money amount, non-alphanumeric tokens, or stopwords
            continue
        else:
            cleaned.append(token)
    return ' '.join(cleaned)

df['title_cl'] = df['title'].apply(clean_titles)
# Chọn các features quan trọng cho model
final_features = [
    'view_count', 'likes', 'dislikes', 'comment_count',
    'title_length', 'num_tags', 'title_sentiment',
    'categoryId', 'hours_to_trend'
]
df_final = df[final_features]

# Lưu dữ liệu đã xử lý
df_final.to_csv('processed_youtube_trending.csv', index=False)
