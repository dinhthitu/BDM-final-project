# correlation_analysis.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from preprocessing import load_and_preprocess

def analyze_correlations(df, numeric_features):
    """Phân tích correlation giữa các biến số và với target"""
    # 1. Correlation giữa các features
    plt.figure(figsize=(12, 10))
    corr_matrix = df[numeric_features + ['hours_to_trend']].corr()
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt=".2f")
    plt.title("Correlation Matrix (Including Target Variable)")
    plt.tight_layout()
    plt.savefig('correlation_matrix.png')
    plt.close()
    
    # 2. Top features tương quan với target
    target_corr = corr_matrix['hours_to_trend'].drop('hours_to_trend')
    top_correlated = target_corr.abs().sort_values(ascending=False).head(5)
    
    # 3. Visualize pairwise relationships với target
    for feature in top_correlated.index:
        plt.figure(figsize=(8, 5))
        sns.regplot(x=feature, y='hours_to_trend', data=df, 
                   scatter_kws={'alpha':0.3}, line_kws={'color':'red'})
        plt.title(f"Relationship between {feature} and hours_to_trend")
        plt.tight_layout()
        plt.savefig(f'{feature}_vs_target.png')
        plt.close()
    
    return {
        'correlation_matrix': corr_matrix,
        'top_correlated_features': top_correlated
    }

if __name__ == "__main__":
    # Load dữ liệu đã qua xử lý
    df, numeric_features, _ = load_and_preprocess('US_youtube_trending_data.csv')
    
    # Phân tích correlation
    results = analyze_correlations(df, numeric_features)
    
    # Lưu kết quả
    pd.DataFrame(results['top_correlated_features']).to_csv('top_correlated_features.csv')
    print("Analysis completed. Results saved to:")
    print("- correlation_matrix.png")
    print("- feature_vs_target.png (for top features)")
    print("- top_correlated_features.csv")


# model_analysis.py (updated)
# ... (phần import giữ nguyên)

def main():
    # Load và preprocess data
    df, numeric_features, categorical_features = load_and_preprocess('US_youtube_trending_data.csv')
    
    # Chuẩn bị dữ liệu
    X = df[numeric_features + categorical_features]
    y = df['hours_to_trend']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Dictionary tên category
    category_names = {c
        1: 'Film & Animation',
        2: 'Autos & Vehicles',
        # ... (thêm đầy đủ)
    }
    
    # 1. Model training và selection
    best_model, best_model_name, model_results = train_and_select_model(
        X_train[numeric_features], y_train, 
        X_test[numeric_features], y_test
    )
    print(f"\nBest model: {best_model_name}")
    print(pd.DataFrame(model_results))
    
    # 2. SHAP analysis
    shap_values, top_features = analyze_with_shap(best_model, X_test[numeric_features], numeric_features)
    print(f"\nTop 3 important features: {top_features}")
    
    # 3. Phân tích ảnh hưởng theo category
    for feature in top_features:
        plot_category_impact(X_test, shap_values, feature, numeric_features, category_names)
        
        # Phân tích thống kê
        print(f"\nPhân tích chi tiết cho feature: {feature}")
        stats = df.groupby('categoryId')[feature].agg(['mean', 'median', 'std'])
        print(stats.sort_values('mean', ascending=False).head(5))
