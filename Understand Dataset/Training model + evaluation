import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
import lightgbm as lgb

# Load dữ liệu
df = pd.read_csv('US_youtube_trending_data.csv')

# Tính toán các features về engagement
df['engagement_rate'] = (df['likes'] + df['dislikes'] + df['comment_count']) / (df['view_count'] + 1e-6)
df['like_dislike_ratio'] = df['likes'] / (df['dislikes'] + 1e-6)
df['comment_view_ratio'] = df['comment_count'] / (df['view_count'] + 1e-6)
df['dislikes_per_comment'] = df['dislikes'] / (df['comment_count'] + 1e-6)

# Tính toán các features về velocity
df['publishedAt'] = pd.to_datetime(df['publishedAt'])
df['trending_date'] = pd.to_datetime(df['trending_date'])
df['days_since_publication'] = (df['trending_date'] - df['publishedAt']).dt.days
df['likes_per_day'] = df['likes'] / (df['days_since_publication'] + 1e-6)
df['comments_per_day'] = df['comment_count'] / (df['days_since_publication'] + 1e-6)
df['view_velocity'] = np.log(df['view_count'] + 1) / (df['days_since_publication'] + 1)

# Chọn features và target
features = [
    'view_count', 'likes', 'dislikes', 'comment_count',
    'engagement_rate', 'like_dislike_ratio', 'comment_view_ratio',
    'dislikes_per_comment', 'days_since_publication', 'likes_per_day',
    'comments_per_day'
]
target = 'view_velocity'

# Lấy tập dữ liệu chứa đầy đủ cả features và target
X = df[features]
y = df[target]

# Gộp lại để xử lý missing values cho toàn bộ
full_data = X.copy()
full_data['target'] = y

# Xử lý NaN hoặc Inf
full_data = full_data.replace([np.inf, -np.inf], np.nan).dropna()

# Tách lại
X_clean = full_data[features]
y_clean = full_data['target']

# Chia tập train/test
X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)

# -------------------------- XGBoost --------------------------
# Tạo DMatrix
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Tham số
params_xgb = {
    'objective': 'reg:squarederror',
    'eval_metric': 'rmse',
    'eta': 0.1,
    'max_depth': 6,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'seed': 42,
    'gamma': 0.1,
    'min_child_weight': 3
}

# Huấn luyện
num_rounds = 200
model_xgb = xgb.train(params_xgb, dtrain, num_rounds)

# Dự đoán
y_pred_xgb = model_xgb.predict(dtest)

# Đánh giá
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mse_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)

print("XGBoost Performance:")
print(f"MAE: {mae_xgb:.6f}")
print(f"MSE: {mse_xgb:.6f}")
print(f"RMSE: {rmse_xgb:.6f}")
print(f"R2 Score: {r2_xgb:.6f}")

# Feature importance
xgb.plot_importance(model_xgb, max_num_features=10)
plt.title('XGBoost Feature Importance')
plt.show()

# -------------------------- LightGBM --------------------------
train_data = lgb.Dataset(X_train, label=y_train)
test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)

params_lgb = {
    'objective': 'regression',
    'metric': 'rmse',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': -1,
    'min_data_in_leaf': 20,
    'lambda_l1': 0.1,
    'lambda_l2': 0.1
}

# Huấn luyện
model_lgb = lgb.train(params_lgb,
                      train_data,
                      num_boost_round=200,
                      valid_sets=[test_data])


# Dự đoán
y_pred_lgb = model_lgb.predict(X_test, num_iteration=model_lgb.best_iteration)

# Đánh giá
mae_lgb = mean_absolute_error(y_test, y_pred_lgb)
mse_lgb = mean_squared_error(y_test, y_pred_lgb)
rmse_lgb = np.sqrt(mse_lgb)
r2_lgb = r2_score(y_test, y_pred_lgb)

print("\nLightGBM Performance:")
print(f"MAE: {mae_lgb:.6f}")
print(f"MSE: {mse_lgb:.6f}")
print(f"RMSE: {rmse_lgb:.6f}")
print(f"R2 Score: {r2_lgb:.6f}")

# Feature importance
lgb.plot_importance(model_lgb, max_num_features=10)
plt.title('LightGBM Feature Importance')
plt.show()

# -------------------------- So sánh --------------------------
results = pd.DataFrame({
    'Model': ['XGBoost', 'LightGBM'],
    'MAE': [mae_xgb, mae_lgb],
    'MSE': [mse_xgb, mse_lgb],
    'RMSE': [rmse_xgb, rmse_lgb],
    'R2 Score': [r2_xgb, r2_lgb]
})

print("\nModel Comparison:")
print(results)

# -------------------------- Lựa chọn Best Model --------------------------
if r2_xgb > r2_lgb:
    best_model_name = "XGBoost"
    best_model = model_xgb
    best_predictions = y_pred_xgb
else:
    best_model_name = "LightGBM"
    best_model = model_lgb
    best_predictions = y_pred_lgb

print(f"\n✅ Best Model Selected: {best_model_name}")
