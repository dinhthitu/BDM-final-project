import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
import lightgbm as lgb
from xgboost import XGBRegressor

# Load dữ liệu
df = pd.read_csv('US_youtube_trending_data.csv')

# Tính toán các features về engagement
df['engagement_rate'] = (df['likes'] + df['dislikes'] + df['comment_count']) / (df['view_count'] + 1e-6)
df['like_dislike_ratio'] = df['likes'] / (df['dislikes'] + 1e-6)
df['comment_view_ratio'] = df['comment_count'] / (df['view_count'] + 1e-6)
df['dislikes_per_comment'] = df['dislikes'] / (df['comment_count'] + 1e-6)

# Tính toán các features về velocity
df['publishedAt'] = pd.to_datetime(df['publishedAt'])
df['trending_date'] = pd.to_datetime(df['trending_date'])
df['days_since_publication'] = (df['trending_date'] - df['publishedAt']).dt.days
df['likes_per_day'] = df['likes'] / (df['days_since_publication'] + 1e-6)
df['comments_per_day'] = df['comment_count'] / (df['days_since_publication'] + 1e-6)
df['view_velocity'] = np.log(df['view_count'] + 1) / (df['days_since_publication'] + 1)

# Chọn features và target
features = [
    'view_count', 'likes', 'dislikes', 'comment_count',
    'engagement_rate', 'like_dislike_ratio', 'comment_view_ratio',
    'dislikes_per_comment', 'days_since_publication', 'likes_per_day',
    'comments_per_day'
]
target = 'view_velocity'

# Lấy tập dữ liệu chứa đầy đủ cả features và target
X = df[features]
y = df[target]

# Gộp lại để xử lý missing values cho toàn bộ
full_data = X.copy()
full_data['target'] = y

# Xử lý NaN hoặc Inf
full_data = full_data.replace([np.inf, -np.inf], np.nan).dropna()

# Tách lại
X_clean = full_data[features]
y_clean = full_data['target']
# Lưu lại file đã được tiền xử lý
preprocessed_data = X_clean.copy()
preprocessed_data[target] = y_clean

# Thêm các thông tin khác nếu cần (ví dụ: video_id, title nếu bạn muốn giữ lại)
additional_columns = ['video_id', 'tags', 'title', 'publishedAt', 'trending_date', 'categoryId']  # Thay đổi theo nhu cầu
for col in additional_columns:
    if col in df.columns:
        # Lấy chỉ số tương ứng từ dataframe gốc
        preprocessed_data[col] = df.loc[preprocessed_data.index, col]

# Lưu thành file CSV
preprocessed_data.to_csv('preprocessed_youtube_trending_data.csv', index=False)
print("✅ Đã lưu file tiền xử lý: 'preprocessed_youtube_trending_data.csv'")


# Chia tập train/test
X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)

# -------------------------- XGBoost --------------------------
# Tạo DMatrix
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Tham số
model_xgb = XGBRegressor(
    objective='reg:squarederror',
    eval_metric='rmse',
    learning_rate=0.1,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    gamma=0.1,
    min_child_weight=3,
    random_state=42,
    n_estimators=200
)

# Huấn luyện
model_xgb.fit(X_train, y_train)

# Dự đoán
y_pred_xgb = model_xgb.predict(X_test)

# Đánh giá
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mse_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)

print("XGBoost Performance:")
print(f"MAE: {mae_xgb:.6f}")
print(f"MSE: {mse_xgb:.6f}")
print(f"RMSE: {rmse_xgb:.6f}")
print(f"R2 Score: {r2_xgb:.6f}")

# Feature importance
xgb.plot_importance(model_xgb, max_num_features=10)
plt.title('XGBoost Feature Importance')
plt.show()

# -------------------------- LightGBM --------------------------
train_data = lgb.Dataset(X_train, label=y_train)
test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)

params_lgb = {
    'objective': 'regression',
    'metric': 'rmse',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': -1,
    'min_data_in_leaf': 20,
    'lambda_l1': 0.1,
    'lambda_l2': 0.1
}

# Huấn luyện
model_lgb = lgb.train(params_lgb,
                      train_data,
                      num_boost_round=100,
                      valid_sets=[test_data],
                     )


# Dự đoán
y_pred_lgb = model_lgb.predict(X_test, num_iteration=model_lgb.best_iteration)

# Đánh giá
mae_lgb = mean_absolute_error(y_test, y_pred_lgb)
mse_lgb = mean_squared_error(y_test, y_pred_lgb)
rmse_lgb = np.sqrt(mse_lgb)
r2_lgb = r2_score(y_test, y_pred_lgb)

print("\nLightGBM Performance:")
print(f"MAE: {mae_lgb:.6f}")
print(f"MSE: {mse_lgb:.6f}")
print(f"RMSE: {rmse_lgb:.6f}")
print(f"R2 Score: {r2_lgb:.6f}")

# Feature importance
lgb.plot_importance(model_lgb, max_num_features=10)
plt.title('LightGBM Feature Importance')
plt.show()

# -------------------------- So sánh --------------------------
results = pd.DataFrame({
    'Model': ['XGBoost', 'LightGBM'],
    'MAE': [mae_xgb, mae_lgb],
    'MSE': [mse_xgb, mse_lgb],
    'RMSE': [rmse_xgb, rmse_lgb],
    'R2 Score': [r2_xgb, r2_lgb]
})

print("\nModel Comparison:")
print(results)

# -------------------------- Lựa chọn Best Model --------------------------
if r2_xgb > r2_lgb:
    best_model_name = "XGBoost"
    best_model = model_xgb
    best_predictions = y_pred_xgb
else:
    best_model_name = "LightGBM"
    best_model = model_lgb
    best_predictions = y_pred_lgb

print(f"\n✅ Best Model Selected: {best_model_name}")
import joblib

# Lưu model XGBoost để test.py có thể dùng lại
if best_model_name == "XGBoost":
    joblib.dump(best_model, 'model_xgb.joblib')
X_test.to_csv('X_test.csv', index=True)
X_train.to_csv('X_train.csv', index=False)

import shap

# Sau khi huấn luyện mô hình
import joblib
import shap

# Lưu model tốt nhất
if best_model_name == "XGBoost":
    joblib.dump(model_xgb, 'model_xgb.joblib')  # model_xgb là XGBRegressor
    explainer = shap.Explainer(model_xgb, X_test)
    shap_values = explainer(X_test)
    joblib.dump(shap_values, 'shap_values_xgb.joblib')
    shap.summary_plot(shap_values, X_test)

elif best_model_name == "LightGBM":
    joblib.dump(model_lgb, 'model_lgb.joblib')
    explainer = shap.Explainer(model_lgb, X_test)
    shap_values = explainer(X_test)
    joblib.dump(shap_values, 'shap_values_lgb.joblib')
    shap.summary_plot(shap_values, X_test)
models = {
    "XGBoost": model_xgb,
    "LightGBM": model_lgb
}
__all__ = ['best_model_name', 'X_train', 'y_train', 'models']
