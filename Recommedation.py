import pandas as pd
import numpy as np
import shap
import json
import joblib
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns

class YouTubeRecommendationSystem:
    def __init__(self, country_code):
        self.country_code = country_code
        sns.set(style='darkgrid', palette='deep', font='DejaVu Sans', font_scale=1.2)
        self.setup_features()
        self.load_data()
        self.X_test = None
        self.shap_values = None
        self.model = None
    
    def load_data(self):
        try:
            # ƒê·ªçc file t·ª´ th∆∞ m·ª•c con t∆∞∆°ng ·ª©ng v·ªõi qu·ªëc gia
            self.df = pd.read_csv(f'{self.country_code}_preprocessed_youtube_trending_data.csv')
            
            missing_features = [f for f in self.features if f not in self.df.columns]
            if missing_features:
                raise ValueError(f"Thi·∫øu c√°c c·ªôt trong self.df: {missing_features}")
            
            with open(f'{self.country_code}_category_id_to_name.json', 'r') as f:
                self.category_names = json.load(f)
            
            self.category_stats = pd.read_csv(f'{self.country_code}_output/{self.country_code}_category_stats.csv')
            self.trending_stats = pd.read_csv(f'{self.country_code}_output/{self.country_code}_trending_stats_by_category.csv')
            self.tag_stats = pd.read_csv(f'{self.country_code}_output/{self.country_code}_most_popular_tags_by_category.csv')
            self.hours_to_trend = pd.read_csv(f'{self.country_code}_output/{self.country_code}_avg_hours_to_trend_by_category.csv')
            
        except Exception as e:
            raise ValueError(f"L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}")

    def setup_features(self):
        self.features = [
            'view_count', 'likes', 'dislikes', 'comment_count',
            'engagement_rate', 'like_dislike_ratio', 'comment_view_ratio',
            'dislikes_per_comment', 'days_since_publication', 'likes_per_day',
            'comments_per_day', 'title_length', 'title_sentiment'
        ]
    
    def load_model_and_shap(self):
        try:
            # ƒê·ªçc file JSON ƒë·ªÉ bi·∫øt m√¥ h√¨nh t·ªët nh·∫•t
            with open(f'{self.country_code}_output/{self.country_code}_best_model.json', 'r') as f:
                model_info = json.load(f)
            best_model_name = model_info['best_model']

            # ƒê·ªçc X_test t·ª´ th∆∞ m·ª•c con
            self.X_test = pd.read_csv(f'{self.country_code}_output/{self.country_code}_X_test.csv', index_col=0)
            
            available_features = [f for f in self.features if f in self.X_test.columns]
            if len(available_features) < len(self.features):
                missing = [f for f in self.features if f not in self.X_test.columns]
                raise ValueError(f"Thi·∫øu c√°c c·ªôt trong X_test: {missing}")
            self.X_test = self.X_test[available_features]
            
            # T·∫£i m√¥ h√¨nh v√† SHAP values d·ª±a tr√™n best_model_name
            if best_model_name == "XGBoost":
                self.model = joblib.load(f'{self.country_code}_output/{self.country_code}_model_xgb.joblib')
                self.shap_values = joblib.load(f'{self.country_code}_output/{self.country_code}_shap_values_xgb.joblib')
            else:  # LightGBM
                self.model = joblib.load(f'{self.country_code}_output/{self.country_code}_model_lgb.joblib')
                self.shap_values = joblib.load(f'{self.country_code}_output/{self.country_code}_shap_values_lgb.joblib')
            
        except Exception as e:
            raise ValueError(f"L·ªói khi t·∫£i m√¥ h√¨nh ho·∫∑c SHAP: {str(e)}")
    
    def get_category_insights(self, category_id):
        category_id_str = str(category_id)
        category_id_int = int(category_id)
        category_name = self.category_names.get(category_id_str, f"Category {category_id_str}")

        insights = {
            'name': category_name,
            'general_stats': {},
            'trending_patterns': {},
            'tags': [],
            'time_to_trend': {}
        }

        try:
            if not self.category_stats.empty:
                stats = self.category_stats[self.category_stats['Category'] == category_name]
                if not stats.empty:
                    insights['general_stats'] = {
                        'percentage': float(stats['Percentage'].values[0]),
                        'avg_views': float(stats['Avg Views'].values[0]) if 'Avg Views' in stats else 0,
                        'avg_likes': float(stats['Avg Likes'].values[0]) if 'Avg Likes' in stats else 0
                    }

            if not self.trending_stats.empty:
                patterns = self.trending_stats[self.trending_stats['Danh m·ª•c'] == category_name]
                if not patterns.empty:
                    insights['trending_patterns'] = {
                        'peak_day': patterns.iloc[0].get('Ng√†y ƒë·ªânh', 'N/A'),
                        'peak_hour': patterns.iloc[0].get('Gi·ªù ƒëƒÉng trung b√¨nh', 'N/A'),
                        'avg_time': float(patterns.iloc[0].get('Th·ªùi gian l√™n trending (gi·ªù)', 0))
                    }

            if not self.tag_stats.empty:
                tags_rows = self.tag_stats[self.tag_stats['Category'] == category_name]
                if not tags_rows.empty:
                    valid_tags = [tag for tag in tags_rows['Tag'].head(5).tolist() if tag != '[none]']
                    insights['tags'] = valid_tags

            if not self.hours_to_trend.empty:
                time_stats = self.hours_to_trend[self.hours_to_trend['categoryId'] == category_id_int]
                if not time_stats.empty:
                    print(f"Debug: S·ªë l∆∞·ª£ng m·∫´u cho categoryId={category_id_int} ({self.country_code}): {len(time_stats)}")
                    insights['time_to_trend'] = {
                        'avg': float(time_stats['hours_to_trend'].mean()),
                        'median': float(time_stats['hours_to_trend'].median()),
                        'std': float(time_stats['hours_to_trend'].std()) if len(time_stats['hours_to_trend']) > 1 else None,
                        'sample_count': len(time_stats['hours_to_trend'])
                    }

        except Exception as e:
            pass

        return insights
    
    def generate_shap_recommendations(self, category_data, category_id):
        recommendations = []
        
        try:
            test_indices = self.X_test.index.intersection(category_data.index)
            if len(test_indices) == 0:
                return ["Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch SHAP."], pd.DataFrame()
            
            test_positions = [list(self.X_test.index).index(idx) for idx in test_indices]
            
            missing_features = [f for f in self.features if f not in category_data.columns]
            if missing_features:
                raise ValueError(f"Thi·∫øu c√°c c·ªôt trong category_data: {missing_features}")
            
            missing_test_features = [f for f in self.features if f not in self.X_test.columns]
            if missing_test_features:
                raise ValueError(f"Thi·∫øu c√°c c·ªôt trong X_test: {missing_test_features}")
            
            if category_data[self.features].isna().any().any():
                raise ValueError("D·ªØ li·ªáu ch·ª©a gi√° tr·ªã NaN.")
            
            if isinstance(self.shap_values, shap.Explanation):
                shap_values_array = self.shap_values.values
                shap_feature_names = self.shap_values.feature_names
                if shap_feature_names and shap_feature_names != self.features:
                    raise ValueError(f"T√™n ƒë·∫∑c tr∆∞ng SHAP kh√¥ng kh·ªõp v·ªõi ƒë·∫∑c tr∆∞ng m√¥ h√¨nh.")
            else:
                shap_values_array = self.shap_values
            
            if shap_values_array.shape[1] != len(self.features):
                raise ValueError(f"K√≠ch th∆∞·ªõc SHAP values kh√¥ng kh·ªõp v·ªõi s·ªë ƒë·∫∑c tr∆∞ng.")
            
            category_shap = shap_values_array[test_positions]
            
            shap_df = pd.DataFrame(category_shap, columns=self.features)
            
            if shap_df.isna().any().any():
                raise ValueError("SHAP values ch·ª©a gi√° tr·ªã NaN.")
            
            # T√≠nh feature_importance v·ªõi p25, p75
            feature_importance = pd.DataFrame({
                'feature': self.features,
                'mean_abs_shap': np.abs(category_shap).mean(axis=0),
                'mean_shap': category_shap.mean(axis=0),
                'positive_impact': (category_shap > 0).mean(axis=0),
                'negative_impact': (category_shap < 0).mean(axis=0),
                'p25': [category_data[f].quantile(0.25) for f in self.features],
                'p75': [category_data[f].quantile(0.75) for f in self.features]
            }).sort_values('mean_abs_shap', ascending=False)
            
            total_shap = feature_importance['mean_abs_shap'].sum()
            if total_shap == 0:
                raise ValueError("T·ªïng ƒë√≥ng g√≥p SHAP b·∫±ng 0.")
            feature_importance['percent_contribution'] = feature_importance['mean_abs_shap'] / total_shap * 100
            
            # X√°c ƒë·ªãnh ∆∞u ti√™n
            feature_importance['priority'] = feature_importance['percent_contribution'].apply(
                lambda x: 'Cao' if x > 30 else 'Trung b√¨nh' if x > 10 else 'Th·∫•p'
            )
            
            top_features = feature_importance.head(5)
            
            # T·∫°o heatmap SHAP
            try:
                plt.figure(figsize=(12, 8))
                heatmap_data = feature_importance[['feature', 'percent_contribution', 'positive_impact', 'negative_impact']].set_index('feature')
                heatmap_data.columns = ['% Contribution', 'Positive Impact', 'Negative Impact']
                sns.heatmap(heatmap_data, annot=True, fmt='.2f', cmap='viridis', cbar_kws={'label': 'C∆∞·ªùng ƒë·ªô ·∫£nh h∆∞·ªüng'})
                plt.title(f'·∫¢nh h∆∞·ªüng c·ªßa c√°c ƒë·∫∑c tr∆∞ng ƒë·∫øn t·ªëc ƒë·ªô l∆∞·ª£t xem\nDanh m·ª•c: {self.category_names.get(str(category_id), "Category " + str(category_id))} ({self.country_code})', fontsize=14)
                plt.xlabel('Metrics', fontsize=12)
                plt.ylabel('Features', fontsize=12)
                plt.tight_layout()
                # L∆∞u heatmap v√†o th∆∞ m·ª•c output c·ªßa qu·ªëc gia
                plot_path = f'{self.country_code}_output/{self.country_code}_shap_impact_category_{category_id}.png'
                plt.savefig(plot_path, dpi=300)
                plt.close()
            except Exception as e:
                recommendations.append(f"Kh√¥ng th·ªÉ t·∫°o heatmap SHAP: {str(e)}")
                plot_path = None
            
            # T√≥m t·∫Øt SHAP
            summary = (
                f"üìä T√≥m t·∫Øt ph√¢n t√≠ch SHAP\n"
                f"- Ph√¢n t√≠ch SHAP ƒëo l∆∞·ªùng m·ª©c ƒë·ªô m·ªói y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn t·ªëc ƒë·ªô l∆∞·ª£t xem c·ªßa video.\n"
                f"- Y·∫øu t·ªë t√≠ch c·ª±c gi√∫p video trending nhanh, y·∫øu t·ªë ti√™u c·ª±c c√≥ th·ªÉ c·∫£n tr·ªü.\n"
                f"- 5 y·∫øu t·ªë quan tr·ªçng nh·∫•t:\n"
            )
            for i, row in top_features.iterrows():
                summary += f"  ‚Ä¢ {row['feature']}: {row['percent_contribution']:.1f}% (∆Øu ti√™n: {row['priority']})\n"
            recommendations.append(summary)
            
            # T·∫°o b·∫£ng t√≥m t·∫Øt
            table = (
                f"\nüìã B·∫£ng t√≥m t·∫Øt SHAP\n"
                f"+{'-'*25}+{'-'*12}+{'-'*10}+\n"
                f"| {'Y·∫øu t·ªë':<23} | {'ƒê√≥ng g√≥p':<10} | {'∆Øu ti√™n':<8} |\n"
                f"+{'-'*25}+{'-'*12}+{'-'*10}+\n"
            )
            for i, row in top_features.iterrows():
                table += f"| {row['feature']:<23} | {row['percent_contribution']:<10.1f}% | {row['priority']:<8} |\n"
            table += f"+{'-'*25}+{'-'*12}+{'-'*10}+\n"
            recommendations.append(table)
            
            # Th√™m th√¥ng b√°o v·ªÅ heatmap
            if plot_path:
                recommendations.append(
                    f"üìà Heatmap ·∫£nh h∆∞·ªüng SHAP\n"
                    f"- Xem heatmap t·∫°i: {plot_path}\n"
                    f"- Heatmap hi·ªÉn th·ªã m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa c√°c y·∫øu t·ªë. C·ªôt '% Contribution' cho th·∫•y t·ª∑ l·ªá ƒë√≥ng g√≥p c·ªßa t·ª´ng y·∫øu t·ªë."
                )
            
            # Khuy·∫øn ngh·ªã chi ti·∫øt
            recommendations.append("\nüîç Khuy·∫øn ngh·ªã chi ti·∫øt")
            for i, row in top_features.iterrows():
                feature = row['feature']
                percent_contribution = row['percent_contribution']
                pos_impact = row['positive_impact']
                neg_impact = row['negative_impact']
                p25 = row['p25']
                p75 = row['p75']
                priority = row['priority']
                
                if feature == 'view_count':
                    rec = (f"‚Ä¢ L∆∞·ª£t xem ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i ƒë·∫°t: {p75:,.0f} l∆∞·ª£t trong 24h\n"
                           f"  - L√Ω do: Gi√∫p trending nhanh trong {pos_impact:.0%} video, nh∆∞ng c·∫£n tr·ªü trong {neg_impact:.0%} n·∫øu tƒÉng ch·∫≠m.")
                elif feature == 'likes':
                    rec = (f"‚Ä¢ L∆∞·ª£t th√≠ch ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i ƒë·∫°t: {p75:,.0f} l∆∞·ª£t trong 6h\n"
                           f"  - L√Ω do: TƒÉng t·ª∑ l·ªá like/view (> {(p75/category_data['view_count'].median()):.2%}) gi√∫p trending nhanh.")
                elif feature == 'dislikes':
                    rec = (f"‚Ä¢ L∆∞·ª£t kh√¥ng th√≠ch ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i gi·ªØ: D∆∞·ªõi {p25:,.0f} l∆∞·ª£t trong 24h\n"
                           f"  - L√Ω do: T·ª∑ l·ªá dislike/view cao c·∫£n tr·ªü trending trong {neg_impact:.0%} video.")
                elif feature == 'comment_count':
                    rec = (f"‚Ä¢ B√¨nh lu·∫≠n ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i ƒë·∫°t: {p75:,.0f} b√¨nh lu·∫≠n trong 12h (~{p75/category_data['days_since_publication'].median():.0f}/ng√†y)\n"
                           f"  - L√Ω do: TƒÉng t∆∞∆°ng t√°c gi√∫p trending trong {pos_impact:.0%} video.")
                elif feature == 'engagement_rate':
                    rec = (f"‚Ä¢ T·ª∑ l·ªá t∆∞∆°ng t√°c ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i ƒë·∫°t: >{p75:.2%}\n"
                           f"  - L√Ω do: T∆∞∆°ng t√°c cao th√∫c ƒë·∫©y trending trong {pos_impact:.0%} video.")
                elif feature == 'like_dislike_ratio':
                    rec = (f"‚Ä¢ T·ª∑ l·ªá like/dislike ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i ƒë·∫°t: >{p75:.1f}\n"
                           f"  - L√Ω do: T·ª∑ l·ªá cao gi√∫p trending trong {pos_impact:.0%} video.")
                elif feature == 'comment_view_ratio':
                    rec = (f"‚Ä¢ T·ª∑ l·ªá b√¨nh lu·∫≠n/view ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i ƒë·∫°t: >{p75:.4f} (1 b√¨nh lu·∫≠n/{(1/p75):.0f} l∆∞·ª£t xem)\n"
                           f"  - L√Ω do: TƒÉng t∆∞∆°ng t√°c gi√∫p trending trong {pos_impact:.0%} video.")
                elif feature == 'dislikes_per_comment':
                    rec = (f"‚Ä¢ T·ª∑ l·ªá dislike/b√¨nh lu·∫≠n ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i gi·ªØ: <{p25:.2f}\n"
                           f"  - L√Ω do: T·ª∑ l·ªá cao cho th·∫•y n·ªôi dung g√¢y tranh c√£i, c·∫£n tr·ªü trong {neg_impact:.0%} video.")
                elif feature == 'days_since_publication':
                    rec = (f"‚Ä¢ Th·ªùi gian t·ª´ khi ƒëƒÉng ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i ƒë·∫°t: Trending trong {p25:.0f} ng√†y\n"
                           f"  - L√Ω do: Th·ªùi gian d√†i c·∫£n tr·ªü trending trong {neg_impact:.0%} video v√¨ m·∫•t t√≠nh m·ªõi m·∫ª.")
                elif feature == 'likes_per_day':
                    rec = (f"‚Ä¢ L∆∞·ª£t th√≠ch/ng√†y ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i ƒë·∫°t: {p75:,.0f}/ng√†y\n"
                           f"  - L√Ω do: T·ªëc ƒë·ªô cao gi√∫p trending trong {pos_impact:.0%} video.")
                elif feature == 'comments_per_day':
                    rec = (f"‚Ä¢ B√¨nh lu·∫≠n/ng√†y ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - Ph·∫£i ƒë·∫°t: {p75:,.0f}/ng√†y\n"
                           f"  - L√Ω do: TƒÉng t∆∞∆°ng t√°c gi√∫p trending trong {pos_impact:.0%} video.")
                elif feature == 'title_length':
                    rec = (f"‚Ä¢ ƒê·ªô d√†i ti√™u ƒë·ªÅ ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - N√™n gi·ªØ: Kho·∫£ng {p25:.0f}-{p75:.0f} k√Ω t·ª±\n"
                           f"  - L√Ω do: ƒê·ªô d√†i ph√π h·ª£p gi√∫p tƒÉng t·ªëc ƒë·ªô trending trong {pos_impact:.0%} video.")
                elif feature == 'title_sentiment':
                    rec = (f"‚Ä¢ C·∫£m x√∫c ti√™u ƒë·ªÅ ({percent_contribution:.1f}%, {priority}):\n"
                           f"  - N√™n gi·ªØ: Sentiment > {p75:.2f} (t√≠ch c·ª±c)\n"
                           f"  - L√Ω do: Ti√™u ƒë·ªÅ t√≠ch c·ª±c th√∫c ƒë·∫©y trending trong {pos_impact:.0%} video.")
                recommendations.append(rec)
            
            return recommendations, feature_importance.head(5)
        
        except Exception as e:
            recommendations = [f"Kh√¥ng th·ªÉ ph√¢n t√≠ch SHAP: {str(e)}"]
            return recommendations

    def get_top_velocity_factors(self, category_data):
        if 'view_velocity' in category_data.columns:
            corr = category_data.corr()['view_velocity'].abs().sort_values(ascending=False)
            top_factors = corr[1:4].index.tolist()
            return ", ".join(top_factors)
        return "Kh√¥ng c√≥ d·ªØ li·ªáu view_velocity"
    
    def generate_eda_recommendations(self, insights, top_features, category_data):
        recommendations = []
        
        if insights['trending_patterns']:
            patterns = insights['trending_patterns']
            rec = (f"‚Ä¢ ƒêƒÉng video v√†o {patterns['peak_day']} l√∫c {patterns['peak_hour']} gi·ªù "
                   f"ƒë·ªÉ l√™n trending nhanh (kho·∫£ng {patterns['avg_time']:.1f} gi·ªù). "
                   f"ƒêi·ªÅu n√†y gi√∫p gi·∫£m th·ªùi gian ƒëƒÉng, y·∫øu t·ªë quan tr·ªçng nh·∫•t ({top_features.iloc[0]['percent_contribution']:.1f}%).")
            recommendations.append(rec)
        
        if insights['tags']:
            rec = f"‚Ä¢ S·ª≠ d·ª•ng c√°c tag ph·ªï bi·∫øn: {', '.join(insights['tags'])} ƒë·ªÉ tƒÉng kh·∫£ nƒÉng hi·ªÉn th·ªã."
            recommendations.append(rec)
        
        if insights['time_to_trend']:
            time_stats = insights['time_to_trend']
            if time_stats.get('sample_count', 0) > 1 and time_stats.get('std') is not None and not np.isnan(time_stats['std']) and time_stats['std'] > 0:
                std_text = f"¬±{time_stats['std']:.1f}"
                rec = (f"‚Ä¢ Nh·∫Øm ƒë·∫øn th·ªùi gian trending d∆∞·ªõi {time_stats['median']:.1f} gi·ªù "
                       f"(dao ƒë·ªông {std_text} gi·ªù) ƒë·ªÉ t·ªëi ∆∞u h√≥a t·ªëc ƒë·ªô l∆∞·ª£t xem.")
            else:
                rec = (f"‚Ä¢ Nh·∫Øm ƒë·∫øn th·ªùi gian trending d∆∞·ªõi {time_stats['median']:.1f} gi·ªù "
                       f"ƒë·ªÉ t·ªëi ∆∞u h√≥a t·ªëc ƒë·ªô l∆∞·ª£t xem (d·ªØ li·ªáu h·∫°n ch·∫ø, ch·ªâ d·ª±a tr√™n gi√° tr·ªã trung b√¨nh).")
            recommendations.append(rec)
        
        return recommendations if recommendations else ["Kh√¥ng c√≥ m·∫πo t·ªëi ∆∞u t·ª´ ph√¢n t√≠ch d·ªØ li·ªáu."]
    
    def get_recommendations(self, category_id):
        try:
            category_id = str(category_id)
            
            if category_id not in self.category_names:
                return f"Danh m·ª•c {category_id} kh√¥ng t·ªìn t·∫°i."
            
            insights = self.get_category_insights(category_id)
            category_data = self.df[self.df['categoryId'].astype(str) == category_id]
            
            missing_features = [f for f in self.features if f not in category_data.columns]
            if missing_features:
                shap_recs = [f"Kh√¥ng th·ªÉ ph√¢n t√≠ch SHAP: Thi·∫øu c√°c c·ªôt trong category_data: {missing_features}"]
                top_features = pd.DataFrame()
            else:
                shap_recs, top_features = self.generate_shap_recommendations(category_data, category_id)
            
            eda_recs = self.generate_eda_recommendations(insights, top_features, category_data)
            
            # T·∫°o h√†nh ƒë·ªông ∆∞u ti√™n
            priority_actions = []
            if not top_features.empty:
                for i, row in top_features.head(2).iterrows():
                    if row['feature'] == 'days_since_publication':
                        priority_actions.append(f"‚Ä¢ ƒêƒÉng video v√† qu·∫£ng b√° m·∫°nh trong {row['p25']:.0f} ng√†y ƒë·∫ßu ƒë·ªÉ trending nhanh.")
                    elif row['feature'] == 'comment_count':
                        priority_actions.append(f"‚Ä¢ Khuy·∫øn kh√≠ch {row['p75']:,.0f} b√¨nh lu·∫≠n trong 12h b·∫±ng c√°ch k√™u g·ªçi t∆∞∆°ng t√°c.")
                    elif row['feature'] == 'view_count':
                        priority_actions.append(f"‚Ä¢ ƒê·∫°t {row['p75']:,.0f} l∆∞·ª£t xem trong 24h qua qu·∫£ng c√°o v√† chia s·∫ª.")
                    elif row['feature'] == 'likes_per_day':
                        priority_actions.append(f"‚Ä¢ ƒê·∫°t {row['p75']:,.0f} l∆∞·ª£t th√≠ch m·ªói ng√†y b·∫±ng n·ªôi dung h·∫•p d·∫´n.")
                    elif row['feature'] == 'comments_per_day':
                        priority_actions.append(f"‚Ä¢ ƒê·∫°t {row['p75']:,.0f} b√¨nh lu·∫≠n m·ªói ng√†y qua c√°c c√¢u h·ªèi ho·∫∑c th·∫£o lu·∫≠n.")
                    elif row['feature'] == 'title_length':
                        priority_actions.append(f"‚Ä¢ Gi·ªØ ƒë·ªô d√†i ti√™u ƒë·ªÅ trong kho·∫£ng {row['p25']:.0f}-{row['p75']:.0f} k√Ω t·ª± ƒë·ªÉ t·ªëi ∆∞u h√≥a t·ªëc ƒë·ªô trending.")
                    elif row['feature'] == 'title_sentiment':
                        priority_actions.append(f"‚Ä¢ ƒê·∫£m b·∫£o ti√™u ƒë·ªÅ c√≥ c·∫£m x√∫c t√≠ch c·ª±c (sentiment > {row['p75']:.2f}) ƒë·ªÉ tƒÉng kh·∫£ nƒÉng trending.")
            
            output = [
                f"üìä Khuy·∫øn ngh·ªã cho danh m·ª•c {insights['name']} ({self.country_code})",
                "="*50,
            ]
            if priority_actions:
                output.append("\nüöÄ H√†nh ƒë·ªông ∆∞u ti√™n")
                output.extend(priority_actions)
            output.extend([
                "\nüîç Ph√¢n t√≠ch y·∫øu t·ªë quan tr·ªçng (SHAP)",
                *shap_recs,
                "\nüí° M·∫πo t·ªëi ∆∞u h√≥a n·ªôi dung",
                *eda_recs
            ])
            
            return "\n".join(output)
        
        except Exception as e:
            return f"L·ªói khi t·∫°o khuy·∫øn ngh·ªã: {str(e)}"

if __name__ == "__main__":
    countries = ['US', 'IN', 'BR', 'GB', 'KR']
    print("üéØ H·ªá th·ªëng khuy·∫øn ngh·ªã n·ªôi dung YouTube")
    print("--------------------------------------")
    print("C√°c qu·ªëc gia c√≥ s·∫µn: US, IN, BR, GB, KR")
    
    while True:
        country_input = input("\nNh·∫≠p qu·ªëc gia b·∫°n ƒëang s·ªëng (nh·∫≠p 'exit' ƒë·ªÉ tho√°t): ").strip().upper()
        
        if country_input.lower() == 'exit':
            break
        
        if country_input not in countries:
            print("‚ö†Ô∏è Qu·ªëc gia kh√¥ng h·ª£p l·ªá")
            continue
        
        recommender = YouTubeRecommendationSystem(country_input)
        
        try:
            recommender.load_model_and_shap()
        except Exception as e:
            print(f"Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh ho·∫∑c SHAP: {str(e)}")
            continue
        
        print(f"\nDanh m·ª•c c√≥ s·∫µn ({country_input}):")
        for cat_id, name in recommender.category_names.items():
            print(f"- {cat_id}: {name}")
        
        while True:
            user_input = input("\nNh·∫≠p ID ho·∫∑c t√™n danh m·ª•c (nh·∫≠p 'back' ƒë·ªÉ ch·ªçn qu·ªëc gia kh√°c, 'exit' ƒë·ªÉ tho√°t): ").strip()
            
            if user_input.lower() == 'exit':
                exit()
            elif user_input.lower() == 'back':
                break
            
            category_id = None
            if user_input.isdigit():
                if user_input in recommender.category_names:
                    category_id = user_input
            else:
                for cid, name in recommender.category_names.items():
                    if user_input.lower() in name.lower():
                        category_id = cid
                        break
            
            if not category_id:
                print("‚ö†Ô∏è Danh m·ª•c kh√¥ng t√¨m th·∫•y")
                continue
            
            recommendations = recommender.get_recommendations(category_id)
            print("\n" + recommendations)